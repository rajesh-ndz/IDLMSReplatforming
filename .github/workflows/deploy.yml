name: Deploy Multi License API

on:
  workflow_dispatch:
    inputs:
      ENV:
        description: "Environment to deploy (dev/staging/prod)"
        required: true
        default: "stage"
      ROLLBACK_TAG:
        description: "Optional: previous tag to deploy (e.g., 2025.06.30.02). If blank, deploys new build."
        required: false

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'ap-south-1' }}
  TF_REGION:  ${{ vars.AWS_REGION || 'ap-south-1' }}
  ECR_REPO_NAME: ${{ vars.ECR_REPO_NAME }}
  EC2_INSTANCE_NAME_PATTERN: ${{ vars.EC2_INSTANCE_NAME_PATTERN || format('{0}-idlms-app', github.event.inputs.ENV) }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    permissions:
      contents: read

    steps:
      - name: Checkout code (feature/btl-77)
        uses: actions/checkout@v4
        with:
          ref: feature/btl-77

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure AWS Credentials (static keys)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Who am I?
        run: aws sts get-caller-identity

      - name: Get AWS Account ID
        id: aws-account
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "account_id=$ACCOUNT_ID" >> "$GITHUB_OUTPUT"

      - name: Set dynamic TF & backup buckets
        run: |
          echo "TF_BUCKET=${{ github.event.inputs.ENV }}-btl-idlms-backend-api-tfstate-${{ steps.aws-account.outputs.account_id }}" >> $GITHUB_ENV
          echo "BACKUP_BUCKET=idlms-${{ github.event.inputs.ENV }}-website-built-artifact-${{ steps.aws-account.outputs.account_id }}" >> $GITHUB_ENV
          echo "Using TF_BUCKET=$TF_BUCKET"
          echo "Using BACKUP_BUCKET=$BACKUP_BUCKET"

      - name: Detect backend (S3) region (IMPORTANT)
        run: |
          set -euo pipefail
          BKT_REGION=$(aws s3api get-bucket-location \
            --bucket "${TF_BUCKET}" \
            --query 'LocationConstraint' \
            --output text)
          [ -z "$BKT_REGION" ] || [ "$BKT_REGION" = "None" ] && BKT_REGION="us-east-1"
          echo "BACKEND_REGION=$BKT_REGION" >> $GITHUB_ENV
          echo "Terraform state bucket region: $BKT_REGION"

      - name: Install jq
        run: sudo apt-get update -y && sudo apt-get install -y jq

      # ───────── Optional infra applies — SKIP if folder missing ─────────
      - name: Terraform Apply VPC (skip if folder missing)
        run: |
          if [ ! -d infra/vpc ]; then echo "infra/vpc not found; skipping"; exit 0; fi
          cd infra/vpc
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/vpc/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      - name: Terraform Apply NLB (skip if folder missing)
        run: |
          if [ ! -d infra/nlb ]; then echo "infra/nlb not found; skipping"; exit 0; fi
          cd infra/nlb
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/nlb/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      - name: Terraform Apply API (rest-api)
        run: |
          set -euo pipefail
          cd infra/rest-api

          terraform init -reconfigure -upgrade \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/rest-api/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"

          terraform plan -input=false \
            -var-file="${{ github.event.inputs.ENV }}.tfvars" \
            -out=plan.out

          if terraform show -json plan.out | jq -e '.resource_changes | length > 0' >/dev/null; then
            terraform apply -input=false -auto-approve "plan.out"
          else
            echo "No changes for rest-api."
          fi

      - name: Terraform Apply CloudWatch (skip if folder missing)
        run: |
          if [ ! -d infra/cloudwatch ]; then echo "infra/cloudwatch not found; skipping"; exit 0; fi
          cd infra/cloudwatch
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/cloudwatch/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      - name: Terraform Apply ECR (capture repo URL) (skip if folder missing)
        id: ecr
        run: |
          if [ ! -d infra/ecr ]; then echo "infra/ecr not found; skipping (will derive repo URL)"; exit 0; fi
          cd infra/ecr
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/ecr/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"
          ECR_REPO_URL=$(terraform output -raw ecr_repository_url 2>/dev/null || true)
          if [ -z "$ECR_REPO_URL" ]; then
            ECR_REPO_URL=$(terraform output -json repository_urls | jq -r '.[0]' 2>/dev/null || true)
          fi
          if [ -n "$ECR_REPO_URL" ] && [ "$ECR_REPO_URL" != "null" ]; then
            echo "ECR_REPO_URL=$ECR_REPO_URL" >> $GITHUB_ENV
            echo "Using ECR from Terraform: $ECR_REPO_URL"
          fi

      - name: Terraform Apply SSM (publish app env) (skip if folder missing)
        id: ssm
        run: |
          if [ ! -d infra/ssm ]; then echo "infra/ssm not found; skipping"; exit 0; fi
          cd infra/ssm
          PARAM_NAME="/idlms/shared/${{ github.event.inputs.ENV }}/.env"
          if aws ssm get-parameter --name "$PARAM_NAME" --with-decryption > /dev/null 2>&1; then
            ENV_CONTENT=$(aws ssm get-parameter --name "$PARAM_NAME" --with-decryption --query "Parameter.Value" --output text)
            BASE64_ENV=$(echo "$ENV_CONTENT" | base64 -w 0)
          else
            BASE64_ENV=$(echo "# placeholder env" | base64 -w 0)
          fi
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/ssm/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars" -var="app_env_content=${BASE64_ENV}"
          SSM_ENV_PARAM=$(terraform output -raw ssm_env_param_name | tr -d '\r\n' | sed 's/^ssm:\/\///')
          echo "SSM_ENV_PARAM=$SSM_ENV_PARAM" >> $GITHUB_ENV

      - name: Terraform Apply S3 (skip if folder missing)
        id: s3_apply
        run: |
          if [ ! -d infra/s3 ]; then echo "infra/s3 not found; skipping"; exit 0; fi
          cd infra/s3
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/s3/terraform.tfstate" \
            -backend-config="region=${BACKEND_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      # ───────── Build & push (compose + guaranteed fallback) ─────────
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Generate build tag
        id: tags
        run: |
          DATE_TAG=$(date +'%Y.%m.%d')
          BUILD_NUM=$(printf "%03d" $GITHUB_RUN_NUMBER)
          BUILD_TAG="${DATE_TAG}.${BUILD_NUM}"
          echo "BUILD_TAG=$BUILD_TAG" >> $GITHUB_ENV

      - name: Determine ECR repo URL (robust; tries other region if needed)
        run: |
          set -euo pipefail
          if [ -n "${ECR_REPO_URL:-}" ] && [ "${ECR_REPO_URL}" != "null" ]; then
            echo "Keeping ECR_REPO_URL from Terraform: ${ECR_REPO_URL}"
            HOST=$(echo "$ECR_REPO_URL" | awk -F/ '{print $1}')
            # region is the second-last dot field: account.dkr.ecr.<region>.amazonaws.com
            ECR_REGION=$(echo "$HOST" | awk -F. '{print $(NF-2)}')
            [ -z "$ECR_REGION" ] && ECR_REGION="${AWS_REGION}"
            echo "ECR_REGION=${ECR_REGION}" >> $GITHUB_ENV
            exit 0
          fi

          if [ -n "${{ vars.ECR_REPO_URL || '' }}" ]; then
            URL="${{ vars.ECR_REPO_URL }}"
            echo "ECR_REPO_URL=$URL" >> $GITHUB_ENV
            HOST=$(echo "$URL" | awk -F/ '{print $1}')
            ECR_REGION=$(echo "$HOST" | awk -F. '{print $(NF-2)}')
            [ -z "$ECR_REGION" ] && ECR_REGION="${AWS_REGION}"
            echo "ECR_REGION=${ECR_REGION}" >> $GITHUB_ENV
            exit 0
          fi

          ACCOUNT_ID="${{ steps.aws-account.outputs.account_id }}"
          REPO_NAME="${ECR_REPO_NAME:-${{ github.event.inputs.ENV }}-idlms-api}"
          ECR_REGION="${AWS_REGION}"

          if ! aws ecr describe-repositories --repository-names "$REPO_NAME" --region "$ECR_REGION" >/dev/null 2>&1; then
            for R in ap-south-1 ap-southeast-1; do
              if [ "$R" != "$ECR_REGION" ] && aws ecr describe-repositories --repository-names "$REPO_NAME" --region "$R" >/dev/null 2>&1; then
                ECR_REGION="$R"; break
              fi
            done
          fi
          if ! aws ecr describe-repositories --repository-names "$REPO_NAME" --region "$ECR_REGION" >/dev/null 2>&1; then
            echo "::error::ECR repository '$REPO_NAME' not found. Create it or set repo variable ECR_REPO_URL."
            exit 1
          fi

          ECR_REPO_URL="${ACCOUNT_ID}.dkr.ecr.${ECR_REGION}.amazonaws.com/${REPO_NAME}"
          echo "ECR_REPO_URL=$ECR_REPO_URL" >> $GITHUB_ENV
          echo "ECR_REGION=$ECR_REGION"       >> $GITHUB_ENV
          echo "Resolved ECR_REPO_URL=$ECR_REPO_URL (region $ECR_REGION)"

      - name: Build & push via docker compose if images are defined
        env:
          IMAGE_REPO: ${{ env.ECR_REPO_URL }}
          BUILD_TAG:  ${{ env.BUILD_TAG }}
        run: |
          set -euo pipefail
          if [ -f docker/docker-compose.yml ] && grep -qE '^\s*image:' docker/docker-compose.yml; then
            echo "Found image fields in compose; building & pushing with compose"
            export IMAGE_REPO BUILD_TAG
            sed -E "s|(image:\s*)([^:]+)(:)?(\$\{BUILD_TAG\})?|\\1${IMAGE_REPO}:\${BUILD_TAG}|g" docker/docker-compose.yml > docker/docker-compose.rendered.yml
            docker compose -f docker/docker-compose.rendered.yml build
            docker compose -f docker/docker-compose.rendered.yml push || true
          else
            echo "No 'image:' in compose; will rely on single-image build below."
          fi

      - name: Canonical single-image build & push (fallback/guarantee)
        env:
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}
          BUILD_TAG:    ${{ env.BUILD_TAG }}
          ECR_REGION:   ${{ env.ECR_REGION || env.AWS_REGION }}
        run: |
          set -euo pipefail
          IMAGE_URI="${ECR_REPO_URL}:${BUILD_TAG}"
          LATEST_URI="${ECR_REPO_URL}:latest"
          echo "IMAGE_URI=$IMAGE_URI"   >> $GITHUB_ENV
          echo "LATEST_URI=$LATEST_URI" >> $GITHUB_ENV
          aws ecr get-login-password --region "${ECR_REGION}" | docker login --username AWS --password-stdin "$(echo "$ECR_REPO_URL" | cut -d/ -f1)"
          docker build -t "$IMAGE_URI" -t "$LATEST_URI" -f docker/Dockerfile src
          docker push "$IMAGE_URI"
          docker push "$LATEST_URI"

      - name: Decide tag to deploy
        id: determine-tag
        run: |
          TAG="${{ github.event.inputs.ROLLBACK_TAG }}"
          if [ -z "$TAG" ]; then TAG="${{ env.BUILD_TAG }}"; fi
          echo "TAG_TO_DEPLOY=$TAG" >> $GITHUB_ENV
          echo "Deploying tag: $TAG"

      - name: Upload docker-compose.yml to S3 (rendered with correct ECR repo)
        run: |
          SRC="docker/docker-compose.rendered.yml"
          if [ ! -f "$SRC" ]; then SRC="docker/docker-compose.yml"; fi
          aws s3 cp "$SRC" "s3://${BACKUP_BUCKET}/${{ github.event.inputs.ENV }}/docker-compose.yml" --region "${AWS_REGION}"

      - name: Resolve EC2 INSTANCE_ID by Name tag
        run: |
          set -euo pipefail
          NAME="${EC2_INSTANCE_NAME_PATTERN}"
          IID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=${NAME}" "Name=instance-state-name,Values=running" \
            --query "Reservations[].Instances[].InstanceId" \
            --output text \
            --region "${AWS_REGION}" | awk '{print $1}')
          if [ -z "$IID" ] || [ "$IID" = "None" ]; then
            echo "::error::No running EC2 instance found matching Name='${NAME}' in ${AWS_REGION}"
            exit 1
          fi
          echo "INSTANCE_ID=$IID" >> $GITHUB_ENV
          echo "Resolved INSTANCE_ID=$IID"

      - name: Deploy containers with rollback logic via SSM
        run: |
          TAG_TO_DEPLOY="${{ env.TAG_TO_DEPLOY }}"
          ENV="${{ github.event.inputs.ENV }}"
          ECR_REPO_URL="${{ env.ECR_REPO_URL }}"
          ECR_REGION="${{ env.ECR_REGION || env.AWS_REGION }}"
          AWS_REGION="${{ env.AWS_REGION }}"
          BACKUP_BUCKET="${{ env.BACKUP_BUCKET }}"
          INSTANCE_ID="${{ env.INSTANCE_ID }}"

          if [ -z "$INSTANCE_ID" ]; then
            echo "ERROR: INSTANCE_ID is empty"; exit 1
          fi

          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "$INSTANCE_ID" \
            --comment "Deploy containers with rollback logic" \
            --parameters 'commands=[
              "set -e",
              "cd /home/ubuntu",
              "ENV_CONTENT=$(aws ssm get-parameter --name \"/idlms/shared/'"$ENV"'/.env\" --with-decryption --query \"Parameter.Value\" --output text)",
              "echo \"$ENV_CONTENT\" > .env",
              "echo \"BUILD_TAG='"$TAG_TO_DEPLOY"'\" >> .env",
              "echo \"IMAGE_REPO='"$ECR_REPO_URL"'\" >> .env",
              "grep -q '^PORT='  .env || echo 'PORT=4000' >> .env",
              "grep -q '^PORT1=' .env || echo 'PORT1=4001' >> .env",
              "grep -q '^PORT2=' .env || echo 'PORT2=4002' >> .env",
              "cp .env .env.api1 && sed -i \"s/^PORT=.*/PORT=4000/\" .env.api1",
              "cp .env .env.api2 && sed -i \"s/^PORT=.*/PORT=4001/\" .env.api2",
              "cp .env .env.api3 && sed -i \"s/^PORT=.*/PORT=4002/\" .env.api3",
              "aws s3 cp s3://'"$BACKUP_BUCKET"'/'"$ENV"'/docker-compose.yml docker-compose.yml",
              "if ! command -v docker &> /dev/null; then sudo apt-get update -y && sudo apt-get install -y docker.io; fi",
              "if ! command -v docker-compose &> /dev/null; then curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose && ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose || true; fi",
              "aws ecr get-login-password --region '"$ECR_REGION"' | docker login --username AWS --password-stdin '"${ECR_REPO_URL%/*}"'",
              "docker-compose --env-file .env down || true",
              "docker rmi '"$ECR_REPO_URL"':'"$TAG_TO_DEPLOY"' || true",
              "docker-compose --env-file .env pull --ignore-pull-failures",
              "docker-compose --env-file .env up -d --force-recreate --build",
              "sleep 60",
              "RUNNING=$(docker ps --format '{{.Names}}' | wc -l) && \
               if [ \\\"$RUNNING\\\" -lt 1 ]; then \
                 echo \\\"Deployment failed. Rolling back...\\\"; \
                 PREV_TAG=$(aws ssm get-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --query \\\"Parameter.Value\\\" --output text 2>/dev/null || echo \\\"\\\"); \
                 if [ -n \\\"$PREV_TAG\\\" ]; then \
                   sed -i \\\"/BUILD_TAG=/d\\\" .env; \
                   echo \\\"BUILD_TAG=$PREV_TAG\\\" >> .env; \
                   docker-compose --env-file .env down || true; \
                   docker rmi '"$ECR_REPO_URL"':'"$TAG_TO_DEPLOY"' || true; \
                   docker-compose --env-file .env pull --ignore-pull-failures; \
                   docker-compose --env-file .env up -d --force-recreate --build; \
                 else \
                   echo \\\"No previous tag recorded; leaving current state\\\"; \
                 fi; \
               else \
                 echo \\\"All containers are up. Saving $TAG_TO_DEPLOY as last-successful-build...\\\"; \
                 aws ssm put-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --value \\\"$TAG_TO_DEPLOY\\\" --type String --overwrite; \
               fi"
            ]' \
            --timeout-seconds 900 \
            --region "$AWS_REGION" \
            --output text
