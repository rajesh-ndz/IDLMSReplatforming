name: Deploy Multi License API (reuse platform-main - single)

on:
  workflow_dispatch:
    inputs:
      ENV:
        description: "Environment to deploy (dev/stage/prod)"
        required: true
        default: "stage"
      ROLLBACK_TAG:
        description: "If set (latest or 2025.06.30.002), deploy that tag without building"
        required: false
      GIT_REF:
        description: "Git ref/branch to use for code"
        required: false
        default: "main"

env:
  AWS_REGION: ${{ vars.AWS_REGION }}

permissions:
  id-token: write
  contents: read

concurrency:
  group: deploy-single-${{ github.event.inputs.ENV }}
  cancel-in-progress: false

jobs:
  build_image:
    if: ${{ !github.event.inputs.ROLLBACK_TAG }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    outputs:
      build_tag: ${{ steps.tags.outputs.BUILD_TAG }}
      image_uri: ${{ steps.tags.outputs.IMAGE_URI }}
      latest_uri: ${{ steps.tags.outputs.LATEST_URI }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.GIT_REF }}

      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION."
            exit 1
          fi

      - uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5
          terraform_wrapper: false

      - name: Bootstrap platform-remote terraform + ${ENV}.tfvars
        run: |
          set -euo pipefail
          sudo apt-get update -y && sudo apt-get install -y jq
          ENV_NAME="${{ github.event.inputs.ENV }}"
          REGION="${{ env.AWS_REGION }}"
          case "$ENV_NAME" in
            stage)
              PLATFORM_STATE_BUCKET="stage-btl-idlms-repo-backend-api-tfstate-592776312448"
              PLATFORM_STATE_REGION="ap-south-1"
              ;;
            *)
              echo "::error::No platform_state_bucket mapping for ENV=$ENV_NAME"; exit 1 ;;
          esac
          mkdir -p infra/platform-remote
          cat > infra/platform-remote/provider.tf <<'TF'
          terraform {
            required_version = ">= 1.5.0"
            required_providers {
              aws = { source = "hashicorp/aws", version = ">= 5.0" }
            }
          }
          provider "aws" { region = var.region }
          TF
          cat > infra/platform-remote/variables.tf <<'TF'
          variable "env_name"              { type = string }
          variable "region"                { type = string }
          variable "platform_state_bucket" { type = string }
          variable "platform_state_region" { type = string }
          TF
          cat > infra/platform-remote/main.tf <<'TF'
          locals {
            network_key  = "${var.env_name}/network/terraform.tfstate"
            compute_key  = "${var.env_name}/compute/terraform.tfstate"
            nlb_key      = "${var.env_name}/nlb/terraform.tfstate"
            ecr_key      = "${var.env_name}/ecr/terraform.tfstate"
            rest_api_key = "${var.env_name}/rest-api/terraform.tfstate"
          }
          data "terraform_remote_state" "network" { backend = "s3" config = { bucket = var.platform_state_bucket, key = local.network_key,  region = var.platform_state_region } }
          data "terraform_remote_state" "compute" { backend = "s3" config = { bucket = var.platform_state_bucket, key = local.compute_key,  region = var.platform_state_region } }
          data "terraform_remote_state" "nlb"     { backend = "s3" config = { bucket = var.platform_state_bucket, key = local.nlb_key,     region = var.platform_state_region } }
          data "terraform_remote_state" "ecr"     { backend = "s3" config = { bucket = var.platform_state_bucket, key = local.ecr_key,     region = var.platform_state_region } }
          data "terraform_remote_state" "rest_api"{ backend = "s3" config = { bucket = var.platform_state_bucket, key = local.rest_api_key,region = var.platform_state_region } }
          TF
          cat > infra/platform-remote/outputs.tf <<'TF'
          output "vpc_id"              { value = try(data.terraform_remote_state.network.outputs.vpc_id, null) }
          output "public_subnet_ids"   { value = try(data.terraform_remote_state.network.outputs.public_subnet_ids, []) }
          output "private_subnet_ids"  { value = try(data.terraform_remote_state.network.outputs.private_subnet_ids, []) }
          output "ecr_repository_url"  { value = try(data.terraform_remote_state.ecr.outputs.ecr_repository_url, null) }
          output "compute_instance_id" { value = try(data.terraform_remote_state.compute.outputs.instance_id, null) }
          output "nlb_dns_name"        { value = try(data.terraform_remote_state.nlb.outputs.nlb_dns_name, null) }
          output "nlb_zone_id"         { value = try(data.terraform_remote_state.nlb.outputs.nlb_zone_id, null) }
          output "listener_4000"       { value = try(data.terraform_remote_state.nlb.outputs.listener_4000, null) }
          output "tg_4000"             { value = try(data.terraform_remote_state.nlb.outputs.tg_4000, null) }
          output "apigw_invoke_url"    { value = try(data.terraform_remote_state.rest_api.outputs.invoke_url, null) }
          output "apigw_stage_name"    { value = try(data.terraform_remote_state.rest_api.outputs.stage_name, null) }
          TF
          cat > "infra/platform-remote/${ENV_NAME}.tfvars" <<EOF
          env_name              = "${ENV_NAME}"
          region                = "${REGION}"
          platform_state_bucket = "${PLATFORM_STATE_BUCKET}"
          platform_state_region = "${PLATFORM_STATE_REGION}"
          EOF

      - name: Read platform-main outputs
        id: platform
        run: |
          set -euo pipefail
          cd infra/platform-remote
          terraform init -upgrade
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform output -json > /tmp/platform_remote.json
          ECR_REPO_URL=$(jq -r '(.ecr_repository_url.value // .repository_url.value // .ecr_repo_url.value // empty)' /tmp/platform_remote.json)
          TARGET_INSTANCE_ID=$(jq -r '.compute_instance_id.value // empty' /tmp/platform_remote.json)
          echo "ECR_REPO_URL=$ECR_REPO_URL" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"
          echo "TARGET_INSTANCE_ID=$TARGET_INSTANCE_ID" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Discover ECR repo URL (fallback)
        if: ${{ env.ECR_REPO_URL == '' }}
        run: |
          set -euo pipefail
          AWS_REGION="${{ env.AWS_REGION }}"
          ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
          NAME="$(aws ecr describe-repositories --region "$AWS_REGION" --query 'repositories[].repositoryName' --output text | tr '\t' '\n' | grep -Ei '(^|-)stage(-|$)|idlms|license|api' | head -n1 || true)"
          if [ -z "$NAME" ]; then
            echo "::error::No suitable ECR repository found."; exit 1
          fi
          URL="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${NAME}"
          echo "ECR_REPO_URL=$URL" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Compute account id & artifact bucket
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          BACKUP_BUCKET="idlms-${{ github.event.inputs.ENV }}-built-artifact-${ACCOUNT_ID}"
          echo "BACKUP_BUCKET=$BACKUP_BUCKET" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - uses: aws-actions/amazon-ecr-login@v2

      - name: Generate build tags
        id: tags
        run: |
          if [ -z "${{ env.ECR_REPO_URL }}" ]; then
            echo "::error::ECR_REPO_URL is empty (platform-remote output missing and discovery failed)."
            exit 1
          fi
          DATE_TAG=$(date +'%Y.%m.%d')
          BUILD_NUM=$(printf "%03d" $GITHUB_RUN_NUMBER)
          BUILD_TAG="${DATE_TAG}.${BUILD_NUM}"
          IMAGE_URI="${{ env.ECR_REPO_URL }}:${BUILD_TAG}"
          LATEST_URI="${{ env.ECR_REPO_URL }}:latest"
          echo "BUILD_TAG=$BUILD_TAG"    | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"
          echo "IMAGE_URI=$IMAGE_URI"   | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"
          echo "LATEST_URI=$LATEST_URI" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Build and tag Docker image
        run: docker build -t "${{ env.IMAGE_URI }}" -t "${{ env.LATEST_URI }}" -f docker/Dockerfile src

      - name: Push Docker images to ECR
        run: |
          docker push "${{ env.IMAGE_URI }}"
          docker push "${{ env.LATEST_URI }}"

  deploy:
    runs-on: ubuntu-latest
    needs: [build_image]
    if: ${{ always() }}
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.GIT_REF }}

      - uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5
          terraform_wrapper: false

      - name: Re-read platform-main outputs
        id: platform
        run: |
          set -euo pipefail
          sudo apt-get update -y && sudo apt-get install -y jq
          cd infra/platform-remote
          terraform init -upgrade
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform output -json > /tmp/platform_remote.json
          ECR_REPO_URL=$(jq -r '(.ecr_repository_url.value // .repository_url.value // .ecr_repo_url.value // empty)' /tmp/platform_remote.json)
          TARGET_INSTANCE_ID=$(jq -r '.compute_instance_id.value // empty' /tmp/platform_remote.json)
          echo "ECR_REPO_URL=${ECR_REPO_URL}" >> "$GITHUB_ENV"
          echo "TARGET_INSTANCE_ID=${TARGET_INSTANCE_ID}" >> "$GITHUB_ENV"

      - uses: aws-actions/amazon-ecr-login@v2

      - name: Compute account id & artifact bucket
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          BACKUP_BUCKET="idlms-${{ github.event.inputs.ENV }}-built-artifact-${ACCOUNT_ID}"
          echo "BACKUP_BUCKET=$BACKUP_BUCKET" >> "$GITHUB_ENV"

      - name: Decide tag to deploy
        id: decide
        run: |
          if [ -n "${{ github.event.inputs.ROLLBACK_TAG }}" ]; then
            TAG="${{ github.event.inputs.ROLLBACK_TAG }}"
          elif [ -n "${{ needs.build_image.outputs.build_tag }}" ]; then
            TAG="${{ needs.build_image.outputs.build_tag }}"
          else
            TAG="latest"
          fi
          echo "TAG_TO_DEPLOY=$TAG" | tee -a "$GITHUB_OUTPUT" >> "$GITHUB_ENV"
          echo "Deploying tag: $TAG"

      - name: Upload docker-compose.yml to S3
        run: |
          aws s3 cp docker/docker-compose.yml "s3://${BACKUP_BUCKET}/${{ github.event.inputs.ENV }}/docker-compose.yml" --region "${{ env.AWS_REGION }}"

      # ⬇⬇⬇ FIXED: build deploy.json with jq and pass via file:// to avoid quoting errors
      - name: Deploy containers with rollback via SSM (safe JSON)
        run: |
          set -euo pipefail
          ENV="${{ github.event.inputs.ENV }}"
          AWS_REGION="${{ env.AWS_REGION }}"
          ECR_REPO_URL="${{ env.ECR_REPO_URL }}"
          ECR_REGISTRY="${ECR_REPO_URL%/*}"
          BACKUP_BUCKET="${{ env.BACKUP_BUCKET }}"
          TAG_TO_DEPLOY="${{ env.TAG_TO_DEPLOY }}"
          INSTANCE_ID="${{ env.TARGET_INSTANCE_ID }}"

          jq -n \
            --arg env "$ENV" \
            --arg region "$AWS_REGION" \
            --arg tag "$TAG_TO_DEPLOY" \
            --arg repo "$ECR_REPO_URL" \
            --arg registry "$ECR_REGISTRY" \
            --arg bucket "$BACKUP_BUCKET" \
            '{
              commands: [
                "set -e",
                "cd /home/ubuntu",
                ("ENV_CONTENT=$(aws ssm get-parameter --name \"/idlms/shared/\($env)/.env\" --with-decryption --query \"Parameter.Value\" --output text --region \($region))"),
                "echo \"$ENV_CONTENT\" > .env",
                ("echo \"BUILD_TAG=\($tag)\" >> .env"),
                ("echo \"IMAGE_REPO=\($repo)\" >> .env"),
                ("aws s3 cp s3://\($bucket)/\($env)/docker-compose.yml docker-compose.yml --region \($region)"),
                "if ! command -v docker &> /dev/null; then sudo apt-get update -y && sudo apt-get install -y docker.io; fi",
                "if ! command -v docker-compose &> /dev/null; then curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose && ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose || true; fi",
                ("aws ecr get-login-password --region \($region) | docker login --username AWS --password-stdin \($registry)"),
                "docker-compose --env-file .env down || true",
                ("docker rmi \($repo):\($tag) || true"),
                "docker-compose --env-file .env pull --ignore-pull-failures",
                "docker-compose --env-file .env up -d --force-recreate",
                "sleep 60",
                "RUNNING_CONTAINERS=$(docker ps --format '{{.Names}}' | grep -E \"api1|api2|api3\" | wc -l)",
                ("if [ \"$RUNNING_CONTAINERS\" -ne 3 ]; then echo \"Deployment failed. Rolling back...\"; PREV_TAG=$(aws ssm get-parameter --name \"/idlms/license-api/last-successful-build\" --query \"Parameter.Value\" --output text --region \($region)); echo \"Rolling back to tag: $PREV_TAG\"; sed -i '/BUILD_TAG=/d' .env; echo \"BUILD_TAG=$PREV_TAG\" >> .env; docker-compose --env-file .env down || true; docker rmi \($repo):\($tag) || true; docker-compose --env-file .env pull --ignore-pull-failures; docker-compose --env-file .env up -d --force-recreate; else echo \"All containers are up. Saving \($tag) as last-successful-build...\"; aws ssm put-parameter --name \"/idlms/license-api/last-successful-build\" --value \($tag) --type String --overwrite --region \($region); fi"),
                "docker ps"
              ]
            }' > deploy.json

          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "$INSTANCE_ID" \
            --comment "Deploy containers with rollback logic" \
            --parameters file://deploy.json \
            --timeout-seconds 900 \
            --region "$AWS_REGION"

  verify:
    name: Post-deploy health check
    runs-on: ubuntu-latest
    needs: deploy
    if: ${{ always() && (needs.build_image.result == 'success' || needs.build_image.result == 'skipped') }}
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    steps:
      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION."
            exit 1
          fi

      - uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5
          terraform_wrapper: false

      - name: Read platform-main outputs for instance id
        run: |
          set -euo pipefail
          sudo apt-get update -y && sudo apt-get install -y jq
          cd infra/platform-remote
          terraform init -upgrade
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"
          IID=$(terraform output -raw compute_instance_id || true)
          if [ -z "$IID" ] || [ "$IID" = "null" ]; then
            echo "::error::No compute instance id found in platform-remote outputs."
            exit 1
          fi
          echo "TARGET_INSTANCE_ID=$IID" >> $GITHUB_ENV

      - name: Wait 45 seconds for containers to settle
        run: sleep 45

      - name: Check docker containers via SSM (accept Up when no healthcheck)
        shell: bash
        run: |
          set -euo pipefail
          AWS_REGION="${{ env.AWS_REGION }}"
          INSTANCE_ID="${{ env.TARGET_INSTANCE_ID }}"
          echo "Health check on INSTANCE_ID: $INSTANCE_ID (region: $AWS_REGION)"
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ] || [ "$INSTANCE_ID" = "null" ]; then
            echo "::error::pods not up"
            exit 1
          fi
          cat > check.json <<'JSON'
          {
            "commands": [
              "set -e",
              "echo '--- health check start ---'",
              "if ! command -v docker >/dev/null 2>&1; then echo 'pods not up'; exit 1; fi",
              "NAMES='api1 api2 api3'",
              "FAILED=0",
              "for n in $NAMES; do",
              "  HS=$(docker inspect -f '{{if .State.Health}}{{.State.Health.Status}}{{else}}nohealth{{end}}' $n 2>/dev/null || echo unknown)",
              "  if [ \"$HS\" = healthy ]; then echo \"$n: healthy\";",
              "  elif docker ps --format '{{.Names}} {{.Status}}' | awk -v c=$n '$1==c && $2 ~ /^Up/ {ok=1} END{exit !ok}'; then echo \"$n: Up (no HEALTHCHECK)\";",
              "  else echo \"$n: not running ($HS)\"; FAILED=1; fi;",
              "done",
              "if [ \"$FAILED\" -ne 0 ]; then echo 'pods not up'; exit 1; fi",
              "echo 'pods up'"
            ]
          }
          JSON
          CMD_ID=$(aws ssm send-command --document-name "AWS-RunShellScript" --instance-ids "$INSTANCE_ID" --comment "Post-deploy health check" --parameters file://check.json --query "Command.CommandId" --output text --region "$AWS_REGION")
          while true; do
            STATUS=$(aws ssm list-command-invocations --command-id "$CMD_ID" --details --query 'CommandInvocations[0].Status' --output text --region "$AWS_REGION")
            case "$STATUS" in
              Pending|InProgress|Delayed) sleep 5 ;;
              Success|Cancelled|TimedOut|Failed) break ;;
              *) sleep 5 ;;
            esac
          done
          echo "SSM status: $STATUS"
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --region "$AWS_REGION" --query 'StandardOutputContent' --output text || true
          if [ "$STATUS" != "Success" ]; then
            echo "::error::pods not up"
            exit 1
          fi
