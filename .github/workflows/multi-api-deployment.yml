name: Deploy Multi License API with Rollback Options

on:
  workflow_dispatch:
    inputs:
      ENV:
        description: 'Environment to deploy (dev/staging/prod)'
        required: true
        default: "stage"
      ROLLBACK_TAG:
        description: 'Optional: Previous build tag (e.g., 2025.06.30.02). If left blank, deploys latest.'
        required: false

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  TF_BUCKET: ${{ github.event.inputs.ENV }}-btl-idlms-backend-api-tfstate-${{ secrets.AWS_ACCOUNT_ID }}
  TF_REGION: ${{ vars.AWS_REGION }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    permissions:
      id-token: write
      contents: read
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout feature/btl-77 codebase
        uses: actions/checkout@v4
        with:
          ref: feature/btl-77

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get AWS Account ID
        id: aws-account
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "account_id=$ACCOUNT_ID" >> "$GITHUB_OUTPUT"

      - name: Set dynamic backup bucket name
        run: echo "BACKUP_BUCKET=idlms-${{ github.event.inputs.ENV }}-built-artifact-${{ steps.aws-account.outputs.account_id }}" >> $GITHUB_ENV

      - name: Sanity check IDs
        run: |
          echo "TF_BUCKET uses secrets.AWS_ACCOUNT_ID = ${{ secrets.AWS_ACCOUNT_ID }}"
          echo "STS says account_id                 = ${{ steps.aws-account.outputs.account_id }}"

      # ========= VPC =========
      - name: Terraform Init VPC
        working-directory: infra/vpc
        run: |
          terraform init \
            -backend-config="bucket=${TF_BUCKET}" \
            -backend-config="key=${{ github.event.inputs.ENV }}/vpc/terraform.tfstate" \
            -backend-config="region=${TF_REGION}" \
            -reconfigure -input=false

      - name: Adopt IAM (import if missing)
        working-directory: infra/vpc
        env:
          ENV_NAME: ${{ github.event.inputs.ENV }}
          ACCOUNT_ID: ${{ steps.aws-account.outputs.account_id }}
        run: |
          set -euo pipefail
          set -x

          TFVARS_FILE="${ENV_NAME}.tfvars"
          ROLE="ec2_ssm_role-${ENV_NAME}"
          PROFILE="${ENV_NAME}-ec2_ssm_profile"

          in_state() {
            local addr="$1"
            terraform state list | grep -qx "$addr"
          }

          try_import() {
            local addr="$1" id="$2"
            if ! in_state "$addr"; then
              echo "Importing $addr -> $id"
              # IMPORTANT: pass var-file so required variables are satisfied during import
              terraform import -input=false -var-file="$TFVARS_FILE" "$addr" "$id" || true
            else
              echo "Already in state: $addr"
            fi
          }

          # Role & Instance Profile
          try_import aws_iam_role.ec2_ssm_role                "$ROLE"
          try_import aws_iam_instance_profile.ec2_ssm_profile "$PROFILE"

          # Policies (deterministic ARNs)
          while read -r NAME ADDR; do
            ARN="arn:aws:iam::${ACCOUNT_ID}:policy/${NAME}"
            try_import "$ADDR" "$ARN"
          done <<'LIST'
          '"'"${ENV_NAME}"'"'-ec2-s3-docker-backup-access aws_iam_policy.s3_docker_backup_access
          '"'"${ENV_NAME}"'"'-ec2-ecr-pull-access         aws_iam_policy.ecr_pull
          '"'"${ENV_NAME}"'"'-ec2-elb-describe-access     aws_iam_policy.elb_describe
          '"'"${ENV_NAME}"'"'-ec2-ssm-describe-instance   aws_iam_policy.ssm_debug
          '"'"${ENV_NAME}"'"'-ec2-describe-instances      aws_iam_policy.ec2_describe
          '"'"${ENV_NAME}"'"'-ec2-ssm-get-parameter       aws_iam_policy.ssm_get_parameter
          LIST

          echo "----- State after adoption (first 100) -----"
          terraform state list | sed -n '1,100p'

      - name: Terraform Apply VPC
        working-directory: infra/vpc
        run: terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      # ========= NLB =========
      - name: Terraform Apply NLB
        if: github.event_name == 'workflow_dispatch' || contains(join(github.event.commits.*.modified), 'infra/')
        working-directory: infra/nlb
        run: |
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/nlb/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      # ========= API Gateway =========
      - name: Terraform Apply API Gateway
        if: github.event_name == 'workflow_dispatch' || contains(join(github.event.commits.*.modified), 'infra/')
        working-directory: infra/rest-api
        run: |
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/rest-api/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform refresh -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      # ========= CloudWatch =========
      - name: Terraform Apply CloudWatch
        if: github.event_name == 'workflow_dispatch' || contains(join(github.event.commits.*.modified), 'infra/')
        working-directory: infra/cloudwatch
        run: |
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/cloudwatch/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      # ========= ECR =========
      - name: Terraform Apply ECR
        id: ecr
        working-directory: infra/ecr
        run: |
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/ecr/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"
          ECR_REPO_URL="$(terraform output -raw ecr_repository_url | tr -d '\r\n')"
          echo "ECR_REPO_URL=$ECR_REPO_URL" >> $GITHUB_ENV
          echo "Using ECR: $ECR_REPO_URL"

      # ========= SSM =========
      - name: Terraform Apply SSM
        id: ssm
        working-directory: infra/ssm
        run: |
          PARAM_NAME="/idlms/shared/${{ github.event.inputs.ENV }}/.env"
          if aws ssm get-parameter --name "$PARAM_NAME" --with-decryption > /dev/null 2>&1; then
            ENV_CONTENT=$(aws ssm get-parameter --name "$PARAM_NAME" --with-decryption --query "Parameter.Value" --output text)
            BASE64_ENV=$(echo "$ENV_CONTENT" | base64 -w 0)
          else
            BASE64_ENV=$(echo "# placeholder env" | base64 -w 0)
          fi

          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/ssm/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars" -var="app_env_content=${BASE64_ENV}"

          SSM_ENV_PARAM=$(terraform output -raw ssm_env_param_name | tr -d '\r\n' | sed 's/^ssm:\/\///')
          echo "SSM_ENV_PARAM=$SSM_ENV_PARAM" >> $GITHUB_ENV

      # ========= S3 (artifact) =========
      - name: Terraform Apply S3
        id: s3_apply
        working-directory: infra/s3
        run: |
          terraform init -backend-config="bucket=${TF_BUCKET}" -backend-config="key=${{ github.event.inputs.ENV }}/s3/terraform.tfstate" -backend-config="region=${TF_REGION}"
          terraform apply -auto-approve -var-file="${{ github.event.inputs.ENV }}.tfvars"

      - name: Upload docker-compose.yml to S3
        run: |
          echo "Uploading to bucket: $BACKUP_BUCKET"
          aws s3 cp docker/docker-compose.yml "s3://$BACKUP_BUCKET/${{ github.event.inputs.ENV }}/docker-compose.yml"

      # ========= Docker build & push =========
      - name: Print ECR URL
        run: echo "Using ECR:$ECR_REPO_URL"

      - name: Log in to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Generate build tags
        id: tags
        run: |
          ECR_REPO_URL="${{ env.ECR_REPO_URL }}"
          DATE_TAG=$(date +'%Y.%m.%d')
          BUILD_NUM=$(printf "%03d" $GITHUB_RUN_NUMBER)
          BUILD_TAG="${DATE_TAG}.${BUILD_NUM}"
          IMAGE_URI="${ECR_REPO_URL}:${BUILD_TAG}"
          LATEST_URI="${ECR_REPO_URL}:latest"

          echo "IMAGE_URI=$IMAGE_URI" >> $GITHUB_ENV
          echo "LATEST_URI=$LATEST_URI" >> $GITHUB_ENV
          echo "BUILD_TAG=$BUILD_TAG" >> $GITHUB_ENV

      - name: Build and tag Docker image
        run: docker build -t "$IMAGE_URI" -t "$LATEST_URI" -f docker/Dockerfile src

      - name: Push Docker images to ECR
        run: |
          docker push "$IMAGE_URI"
          docker push "$LATEST_URI"

      - name: Determine tag to deploy
        id: determine-tag
        run: |
          TAG="${{ github.event.inputs.ROLLBACK_TAG }}"
          if [ -z "$TAG" ]; then
            TAG="${{ env.BUILD_TAG }}"
          fi
          echo "TAG_TO_DEPLOY=$TAG" >> $GITHUB_ENV

      - name: Deploy containers with rollback logic via SSM
        run: |
          TAG_TO_DEPLOY="${{ env.TAG_TO_DEPLOY }}"
          ENV="${{ github.event.inputs.ENV }}"
          ECR_REPO_URL="${{ env.ECR_REPO_URL }}"
          AWS_REGION="${{ env.AWS_REGION }}"
          BACKUP_BUCKET="${{ env.BACKUP_BUCKET }}"

          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=Backend API IDLMS-${ENV}" "Name=instance-state-name,Values=running" \
            --query "Reservations[].Instances[].InstanceId" \
            --region "$AWS_REGION" \
            --output text)

          if [ -z "$INSTANCE_ID" ]; then
            echo "ERROR: No running EC2 instance found for environment $ENV"
            exit 1
          fi

          echo "Deploying tag: $TAG_TO_DEPLOY"

          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "$INSTANCE_ID" \
            --comment "Deploy containers with rollback logic" \
            --parameters 'commands=[
              "set -e",
              "cd /home/ubuntu",
              "ENV_CONTENT=$(aws ssm get-parameter --name \"/idlms/shared/'"$ENV"'/.env\" --with-decryption --query \"Parameter.Value\" --output text)",
              "echo \"$ENV_CONTENT\" > .env",
              "echo \"BUILD_TAG='"$TAG_TO_DEPLOY"'\" >> .env",
              "echo \"IMAGE_REPO='"$ECR_REPO_URL"'\" >> .env",
              "aws s3 cp s3://'"$BACKUP_BUCKET"'/'"$ENV"'/docker-compose.yml docker-compose.yml",
              "if ! command -v docker &> /dev/null; then sudo apt-get update -y && sudo apt-get install -y docker.io; fi",
              "if ! command -v docker-compose &> /dev/null; then curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose && ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose || true; fi",
              "aws ecr get-login-password --region '"$AWS_REGION"' | docker login --username AWS --password-stdin '"${ECR_REPO_URL%/*}"'",
              "docker-compose --env-file .env down || true",
              "docker rmi ${IMAGE_REPO}:${BUILD_TAG} || true",
              "docker-compose --env-file .env pull --ignore-pull-failures",
              "docker-compose --env-file .env up -d --force-recreate --build",
              "sleep 60",
              "RUNNING_CONTAINERS=$(docker ps --format '{{.Names}}' | grep -E \\\"api1|api2|api3\\\" | wc -l) && \
              if [ \\\"$RUNNING_CONTAINERS\\\" -ne 3 ]; then \
               echo \\\"Deployment failed. Rolling back...\\\"; \
               PREV_TAG=$(aws ssm get-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --query \\\"Parameter.Value\\\" --output text); \
               echo \\\"Rolling back to tag: $PREV_TAG\\\"; \
               sed -i \\\"/BUILD_TAG=/d\\\" .env; \
               echo \\\"BUILD_TAG=$PREV_TAG\\\" >> .env; \
               docker-compose --env-file .env down || true; \
               docker rmi ${IMAGE_REPO}:${BUILD_TAG} || true; \
               docker-compose --env-file .env pull --ignore-pull-failures; \
               docker-compose --env-file .env up -d --force-recreate --build; \
             else \
               echo \\\"All containers are up. Saving $TAG_TO_DEPLOY as last-successful-build...\\\"; \
               aws ssm put-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --value \\\"$TAG_TO_DEPLOY\\\" --type String --overwrite; \
             fi"
           ]' \
           --timeout-seconds 900 \
           --region "$AWS_REGION"
