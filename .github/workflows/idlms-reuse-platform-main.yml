name: Deploy Multi License API (reuse platform-main)

on:
  workflow_dispatch:
    inputs:
      ENV:
        description: "Environment to deploy (dev/stage/prod)"
        required: true
        default: "stage"
      ROLLBACK_TAG:
        description: "If set (latest or 2025.06.30.002), deploy that tag without building"
        required: false
      GIT_REF:
        description: "Git ref/branch to use for code & TF"
        required: false
        default: "feature/btl-77"

env:
  AWS_REGION: ${{ vars.AWS_REGION }}

permissions:
  id-token: write
  contents: read

concurrency:
  group: deploy-single-${{ github.event.inputs.ENV }}
  cancel-in-progress: false

jobs:
  # ───────────────────────────── Build Image (only when no rollback tag) ─────────────────────────────
  build_image:
    if: ${{ !github.event.inputs.ROLLBACK_TAG }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    outputs:
      build_tag: ${{ steps.tags.outputs.BUILD_TAG }}
      image_uri: ${{ steps.tags.outputs.IMAGE_URI }}
      latest_uri: ${{ steps.tags.outputs.LATEST_URI }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.GIT_REF }}

      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION or set a default."
            exit 1
          fi

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0
          terraform_wrapper: false

      # Read outputs from platform-main (via IDLMS/infra/platform-remote)
      - name: Read platform-main remote outputs
        id: platform
        run: |
          set -euo pipefail
          cd infra/platform-remote
          terraform init
          terraform apply -auto-approve -refresh-only -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform output -json > /tmp/platform_remote.json
          echo "Platform outputs:" && cat /tmp/platform_remote.json | jq

          ECR_REPO_URL=$(jq -r '.ecr_repository_url.value // empty' /tmp/platform_remote.json)
          echo "ECR_REPO_URL=$ECR_REPO_URL" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

          # Instance (for later deploy/verify)
          TARGET_INSTANCE_ID=$(jq -r '.compute_instance_id.value // empty' /tmp/platform_remote.json)
          echo "TARGET_INSTANCE_ID=$TARGET_INSTANCE_ID" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Compute account id & artifact bucket
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "account_id=$ACCOUNT_ID" >> "$GITHUB_OUTPUT"
          # must match platform-main artifact bucket convention
          BACKUP_BUCKET="idlms-${{ github.event.inputs.ENV }}-built-artifact-${ACCOUNT_ID}"
          echo "BACKUP_BUCKET=$BACKUP_BUCKET" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Log in to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Generate build tags
        id: tags
        run: |
          if [ -z "${{ env.ECR_REPO_URL }}" ]; then
            echo "::error::ECR_REPO_URL is empty (platform-remote not found or ECR not created in platform-main)."
            exit 1
          fi
          DATE_TAG=$(date +'%Y.%m.%d')
          BUILD_NUM=$(printf "%03d" $GITHUB_RUN_NUMBER)
          BUILD_TAG="${DATE_TAG}.${BUILD_NUM}"
          IMAGE_URI="${{ env.ECR_REPO_URL }}:${BUILD_TAG}"
          LATEST_URI="${{ env.ECR_REPO_URL }}:latest"
          echo "BUILD_TAG=$BUILD_TAG"    | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"
          echo "IMAGE_URI=$IMAGE_URI"   | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"
          echo "LATEST_URI=$LATEST_URI" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Build and tag Docker image
        run: docker build -t "${{ env.IMAGE_URI }}" -t "${{ env.LATEST_URI }}" -f docker/Dockerfile src

      - name: Push Docker images to ECR
        run: |
          docker push "${{ env.IMAGE_URI }}"
          docker push "${{ env.LATEST_URI }}"

  # ─────────────────────────────── Consume Infra (read-only) ───────────────────────────────
  consume_infra:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    outputs:
      ecr_repo_url: ${{ steps.platform.outputs.ECR_REPO_URL }}
      target_instance_id: ${{ steps.platform.outputs.TARGET_INSTANCE_ID }}
      backup_bucket: ${{ steps.acct.outputs.BACKUP_BUCKET }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.GIT_REF }}

      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION or set a default."
            exit 1
          fi

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0
          terraform_wrapper: false

      - name: Read platform-main remote outputs
        id: platform
        run: |
          set -euo pipefail
          cd infra/platform-remote
          terraform init
          terraform apply -auto-approve -refresh-only -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform output -json > /tmp/platform_remote.json
          echo "Platform outputs:" && cat /tmp/platform_remote.json | jq

          ECR_REPO_URL=$(jq -r '.ecr_repository_url.value // empty' /tmp/platform_remote.json)
          echo "ECR_REPO_URL=$ECR_REPO_URL" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

          TARGET_INSTANCE_ID=$(jq -r '.compute_instance_id.value // empty' /tmp/platform_remote.json)
          echo "TARGET_INSTANCE_ID=$TARGET_INSTANCE_ID" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

      - name: Compute account id & artifact bucket
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "account_id=$ACCOUNT_ID" >> "$GITHUB_OUTPUT"
          BACKUP_BUCKET="idlms-${{ github.event.inputs.ENV }}-built-artifact-${ACCOUNT_ID}"
          echo "BACKUP_BUCKET=$BACKUP_BUCKET" | tee -a "$GITHUB_ENV" >> "$GITHUB_OUTPUT"

  # ───────────────────────────────────────── Deploy ─────────────────────────────────────────
  deploy:
    runs-on: ubuntu-latest
    needs: [build_image, consume_infra]
    if: ${{ always() }}   # ensure deploy runs even if build_image was skipped
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.GIT_REF }}

      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION or set a default."
            exit 1
          fi

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Re-read platform-main outputs (defensive)
        id: platform
        run: |
          set -euo pipefail
          cd infra/platform-remote
          terraform init
          terraform apply -auto-approve -refresh-only -var-file="${{ github.event.inputs.ENV }}.tfvars"
          terraform output -json > /tmp/platform_remote.json

          ECR_REPO_URL=$(jq -r '.ecr_repository_url.value // empty' /tmp/platform_remote.json)
          TARGET_INSTANCE_ID=$(jq -r '.compute_instance_id.value // empty' /tmp/platform_remote.json)

          echo "ECR_REPO_URL=${ECR_REPO_URL}" >> "$GITHUB_ENV"
          echo "TARGET_INSTANCE_ID=${TARGET_INSTANCE_ID}" >> "$GITHUB_ENV"

      - name: Compute account id & artifact bucket (defensive)
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          BACKUP_BUCKET="idlms-${{ github.event.inputs.ENV }}-built-artifact-${ACCOUNT_ID}"
          echo "BACKUP_BUCKET=$BACKUP_BUCKET" >> "$GITHUB_ENV"

      - name: Upload docker-compose.yml to S3
        run: |
          echo "Uploading docker-compose.yml to s3://${BACKUP_BUCKET}/${{ github.event.inputs.ENV }}/docker-compose.yml"
          aws s3 cp docker/docker-compose.yml "s3://${BACKUP_BUCKET}/${{ github.event.inputs.ENV }}/docker-compose.yml"

      - name: Log in to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Decide tag to deploy
        id: decide
        run: |
          if [ -n "${{ github.event.inputs.ROLLBACK_TAG }}" ]; then
            TAG="${{ github.event.inputs.ROLLBACK_TAG }}"
          elif [ -n "${{ needs.build_image.outputs.build_tag }}" ]; then
            TAG="${{ needs.build_image.outputs.build_tag }}"
          else
            TAG="latest"
          fi
          echo "TAG_TO_DEPLOY=$TAG" | tee -a "$GITHUB_OUTPUT" >> "$GITHUB_ENV"
          echo "Deploying tag: $TAG"

      - name: Deploy containers with rollback logic via SSM
        run: |
          set -euo pipefail
          if [ -z "${{ env.TARGET_INSTANCE_ID }}" ] || [ "${{ env.TARGET_INSTANCE_ID }}" = "null" ]; then
            echo "::error::No compute instance id from platform-main (TARGET_INSTANCE_ID is empty)."
            exit 1
          fi
          ENV="${{ github.event.inputs.ENV }}"
          AWS_REGION="${{ env.AWS_REGION }}"
          ECR_REPO_URL="${{ env.ECR_REPO_URL }}"
          BACKUP_BUCKET="${{ env.BACKUP_BUCKET }}"
          TAG_TO_DEPLOY="${{ env.TAG_TO_DEPLOY }}"

          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "${{ env.TARGET_INSTANCE_ID }}" \
            --comment "Deploy containers with rollback logic" \
            --parameters 'commands=[
              "set -e",
              "cd /home/ubuntu",
              "ENV_CONTENT=$(aws ssm get-parameter --name \"/idlms/shared/'"$ENV"'/.env\" --with-decryption --query \"Parameter.Value\" --output text --region '"$AWS_REGION"')",
              "echo \"$ENV_CONTENT\" > .env",
              "echo \"BUILD_TAG='"$TAG_TO_DEPLOY"'\" >> .env",
              "echo \"IMAGE_REPO='"$ECR_REPO_URL"'\" >> .env",
              "aws s3 cp s3://'"$BACKUP_BUCKET"'/'"$ENV"'/docker-compose.yml docker-compose.yml --region '"$AWS_REGION"'',
              "if ! command -v docker &> /dev/null; then sudo apt-get update -y && sudo apt-get install -y docker.io; fi",
              "if ! command -v docker-compose &> /dev/null; then curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose && ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose || true; fi",
              "aws ecr get-login-password --region '"$AWS_REGION"' | docker login --username AWS --password-stdin '"${ECR_REPO_URL%/*}"''",
              "docker-compose --env-file .env down || true",
              "docker rmi ${ECR_REPO_URL}:${TAG_TO_DEPLOY} || true",
              "docker-compose --env-file .env pull --ignore-pull-failures",
              "docker-compose --env-file .env up -d --force-recreate",
              "sleep 60",
              "RUNNING_CONTAINERS=$(docker ps --format '{{.Names}}' | grep -E \\\"api1|api2|api3\\\" | wc -l) && if [ \"$RUNNING_CONTAINERS\" -ne 3 ]; then echo \\\"Deployment failed. Rolling back...\\\"; PREV_TAG=$(aws ssm get-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --query \\\"Parameter.Value\\\" --output text --region '"$AWS_REGION"'); echo \\\"Rolling back to tag: $PREV_TAG\\\"; sed -i \\\"/BUILD_TAG=/d\\\" .env; echo \\\"BUILD_TAG=$PREV_TAG\\\" >> .env; docker-compose --env-file .env down || true; docker rmi ${ECR_REPO_URL}:${TAG_TO_DEPLOY} || true; docker-compose --env-file .env pull --ignore-pull-failures; docker-compose --env-file .env up -d --force-recreate; else echo \\\"All containers are up. Saving $TAG_TO_DEPLOY as last-successful-build...\\\"; aws ssm put-parameter --name \\\"/idlms/license-api/last-successful-build\\\" --value \\\"$TAG_TO_DEPLOY\\\" --type String --overwrite --region '"$AWS_REGION"'; fi"
            ]' \
            --timeout-seconds 900 \
            --region "$AWS_REGION"

  # ───────────────────────────────────────── Verify ─────────────────────────────────────────
  verify:
    name: Post-deploy health check
    runs-on: ubuntu-latest
    needs: deploy
    if: ${{ always() && (needs.build_image.result == 'success' || needs.build_image.result == 'skipped') }}
    environment: ${{ github.event.inputs.ENV || 'stage' }}
    steps:
      - name: Guard AWS_REGION
        run: |
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "::error::AWS_REGION is empty. Define repo/env variable AWS_REGION or set a default."
            exit 1
          fi

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Read platform-main outputs for instance id
        run: |
          set -euo pipefail
          cd infra/platform-remote
          terraform init
          terraform apply -auto-approve -refresh-only -var-file="${{ github.event.inputs.ENV }}.tfvars"
          IID=$(terraform output -raw compute_instance_id || true)
          if [ -z "$IID" ] || [ "$IID" = "null" ]; then
            echo "::error::No compute instance id found in platform-remote outputs."
            exit 1
          fi
          echo "TARGET_INSTANCE_ID=$IID" >> $GITHUB_ENV

      - name: Wait 45 seconds for containers to settle
        run: sleep 45

      - name: Check docker containers via SSM (accept Up when no healthcheck)
        shell: bash
        run: |
          set -euo pipefail
          AWS_REGION="${{ env.AWS_REGION }}"
          INSTANCE_ID="${{ env.TARGET_INSTANCE_ID }}"
          echo "Health check on INSTANCE_ID: $INSTANCE_ID (region: $AWS_REGION)"
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ] || [ "$INSTANCE_ID" = "null" ]; then
            echo "::error::pods not up"
            exit 1
          fi
          cat > check.json <<'JSON'
          {
            "commands": [
              "set -e",
              "echo '--- health check start ---'",
              "if ! command -v docker >/dev/null 2>&1; then echo 'pods not up'; exit 1; fi",
              "NAMES='api1 api2 api3'",
              "FAILED=0",
              "for n in $NAMES; do",
              "  HS=$(docker inspect -f '{{if .State.Health}}{{.State.Health.Status}}{{else}}nohealth{{end}}' $n 2>/dev/null || echo unknown)",
              "  if [ \"$HS\" = healthy ]; then echo \"$n: healthy\";",
              "  elif docker ps --format '{{.Names}} {{.Status}}' | awk -v c=$n '$1==c && $2 ~ /^Up/ {ok=1} END{exit !ok}'; then echo \"$n: Up (no HEALTHCHECK)\";",
              "  else echo \"$n: not running ($HS)\"; FAILED=1; fi;",
              "done",
              "if [ \"$FAILED\" -ne 0 ]; then echo 'pods not up'; exit 1; fi",
              "echo 'pods up'"
            ]
          }
          JSON
          CMD_ID=$(aws ssm send-command --document-name "AWS-RunShellScript" --instance-ids "$INSTANCE_ID" --comment "Post-deploy health check" --parameters file://check.json --query "Command.CommandId" --output text --region "$AWS_REGION")
          while true; do
            STATUS=$(aws ssm list-command-invocations --command-id "$CMD_ID" --details --query 'CommandInvocations[0].Status' --output text --region "$AWS_REGION")
            case "$STATUS" in
              Pending|InProgress|Delayed) sleep 5 ;;
              Success|Cancelled|TimedOut|Failed) break ;;
              *) sleep 5 ;;
            esac
          done
          echo "SSM status: $STATUS"
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --region "$AWS_REGION" --query 'StandardOutputContent' --output text || true
          if [ "$STATUS" != "Success" ]; then
            echo "::error::pods not up"
            exit 1
          fi